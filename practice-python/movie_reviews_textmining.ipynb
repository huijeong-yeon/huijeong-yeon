# Text Mining Practice Summary

This document summarizes today’s exercises on text mining using Python.
It covers environment setup, data preprocessing, three models (Bag-of-Words, TF–IDF).

---

## 1. Setup & Imports

```python
import random
import numpy as np
import pandas as pd
import nltk
from nltk.corpus import movie_reviews
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn import metrics
from gensim.models import Word2Vec
from sklearn.svm import SVC

## 2. Data Preprocessing

fileids = movie_reviews.fileids()
print(fileids[:5])

raw = movie_reviews.raw(fileids[0])
tokens = [w.lower() for w in movie_reviews.words(fileids[0]) if w.isalpha()]
  
stop = set(nltk.corpus.stopwords.words('english'))
lem = WordNetLemmatizer()
cleaned = [lem.lemmatize(w) for w in tokens if w not in stop]

## 3. Model A: Bag-of-Words + Naïve Bayes

all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())
features = list(all_words)[:2000]
                          
def document_features(words):
    word_set = set(words)
    return {f"contains({w})": (w in word_set) for w in features}
                          
documents = [
  (movie_reviews.words(f), c) 
  for c in movie_reviews.categories() 
  for f in movie_reviews.fileids(c)
]
random.shuffle(documents)
featuresets = [(document_features(d), c) for d, c in documents]
train_set, test_set = featuresets[100:], featuresets[:100]

clf = nltk.NaiveBayesClassifier.train(train_set)
accuracy_a = nltk.classify.accuracy(clf, test_set)
print(f"Model A Accuracy: {accuracy_a:.2%}")     ### accuracy_a: 79.00%
clf.show_most_informative_features(10)

## 4. Model B: TF–IDF + Pipeline

texts = [" ".join(movie_reviews.words(f)) for f in movie_reviews.fileids()]
labels = [movie_reviews.categories(f)[0] for f in movie_reviews.fileids()]
X_train, X_test, y_train, y_test = train_test_split(
  texts, labels, test_size=0.2, random_state=42
)
          
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        lowercase=True,
        token_pattern=r"\b[a-zA-Z]+\b",
        stop_words='english',
        ngram_range=(1,2),
        max_df=0.8,
        min_df=5
    )),
    ('clf', MultinomialNB())
])

pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)    
accuracy_b = metrics.accuracy_score(y_test, y_pred)
print(f"Model B Accuracy: {accuracy_b:.2%}")   ### accuracy_b: 81.25%
print(metrics.classification_report(y_test, y_pred, digits=2)) 
